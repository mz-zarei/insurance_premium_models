{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# load the data set from given path\n",
    "path_to_data = './processed_data/sev_freq_joined_cliped.csv'\n",
    "df = pd.read_csv(path_to_data)\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation Pipeline\n",
    "These transformations are based on Case Study: French Motor Third-Party Liability Claims (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, \\\n",
    "    OrdinalEncoder, PolynomialFeatures, StandardScaler\n",
    "\n",
    "def gen_col_trans(drop=True, standardize=False):\n",
    "    \"\"\"Generate a ColumnTransformer and list of names.\n",
    "    \n",
    "    With drop=False and standardize=False, the transformer corresponds to the GLM of the case study paper.\n",
    "    \n",
    "    drop = False does encode k categories with k binary features (redundant).\n",
    "    standardize = True standardizes numerical features.\n",
    "    \"\"\"\n",
    "    # drop dictionary\n",
    "    dd = {'VehPower': [4],\n",
    "          'VehAge': [1],\n",
    "          'DrivAge': [4],\n",
    "          'VehBrand': ['B1'],\n",
    "          'VehGas': ['Diesel'],\n",
    "          'Region': ['R24']}\n",
    "    if drop is False:\n",
    "        for key, value in dd.items():\n",
    "            dd[key] = None\n",
    "    column_trans = ColumnTransformer(\n",
    "    [\n",
    "    # VehPower 4, 5, 6, 7, 8, 9, drop=4\n",
    "    ('VehPower_cat',\n",
    "      Pipeline([('cut_9', FunctionTransformer(lambda x: np.minimum(x, 9), validate=False)),\n",
    "                ('OHE', OneHotEncoder(categories='auto', drop=dd['VehPower']))]),\n",
    "      ['VehPower']),\n",
    "\n",
    "     # VehAge intervals [0,1), [1, 10], (10, inf), drop=[1,10]\n",
    "     ('VehAge_cat',\n",
    "      Pipeline([('bin', FunctionTransformer(lambda x: np.digitize(np.where(x==10, 9, x), bins=[1,10]), validate=False)),\n",
    "                ('OHE', OneHotEncoder(categories='auto', drop=dd['VehAge']))]),\n",
    "      ['VehAge']),\n",
    "\n",
    "     # DrivAge intervals [18,21), [21,26), [26,31), [31,41), [41,51), [51,71),[71,âˆž), drop=[41,51)\n",
    "     ('DrivAge_cat',\n",
    "      Pipeline([('bin', FunctionTransformer(lambda x: np.digitize(x, bins=[21, 26, 31, 41, 51, 71]), validate=False)),\n",
    "                ('OHE', OneHotEncoder(categories='auto', drop=dd['DrivAge']))]),\n",
    "      ['DrivAge']),\n",
    "\n",
    "     ('BonusMalus',\n",
    "      Pipeline([('cutat150', FunctionTransformer(lambda x: np.minimum(x, 150), validate=False))] + ([('norm', StandardScaler())] if standardize else [])),\n",
    "      ['BonusMalus']),\n",
    "\n",
    "     ('VehBrand_cat', OneHotEncoder(drop=dd['VehBrand']), ['VehBrand']),\n",
    "\n",
    "     ('VehGas_Regular', OneHotEncoder(drop=dd['VehGas']), ['VehGas']),\n",
    "\n",
    "     ('Density_log',\n",
    "      Pipeline([('log', FunctionTransformer(lambda x: np.log(x), validate=False))] + ([('norm', StandardScaler())] if standardize else [])),\n",
    "      ['Density']),\n",
    "\n",
    "     ('Region_cat', OneHotEncoder(drop=dd['Region']), ['Region']), \n",
    "\n",
    "     ('Area_ord', \n",
    "     Pipeline([('OE', OrdinalEncoder()), ('plus_1', FunctionTransformer(lambda x: x+1, validate=False))] + ([('norm', StandardScaler())] if standardize else [])),\n",
    "      ['Area']), \n",
    "    ],\n",
    "    remainder = 'drop')\n",
    "    column_trans_names = ['VehPower_4', 'VehPower_5', 'VehPower_6',\n",
    "                          'VehPower_7', 'VehPower_8', 'VehPower_9',\n",
    "                          'VehAge_[0,1)', 'VehAge_[1, 10]', 'VehAge_(10,inf)',\n",
    "                          'DrivAge_[18,21)', 'DrivAge_[21,26)', 'DrivAge_[26,31)',\n",
    "                          'DrivAge_[31,41)', 'DrivAge_[41,51)', 'DrivAge_[51,71)', 'DrivAge_[71,inf)',\n",
    "                          'BonusMalus',\n",
    "                          'VehBrand_B10', 'VehBrand_B11', 'VehBrand_B12',\n",
    "                          'VehBrand_B13', 'VehBrand_B14', 'VehBrand_B1',\n",
    "                          'VehBrand_B2', 'VehBrand_B3', 'VehBrand_B4',\n",
    "                          'VehBrand_B5', 'VehBrand_B6',\n",
    "                          'VehGas_Diesel', 'VehGas_Regular',\n",
    "                          'Density_log',\n",
    "                          'Region_R11', 'Region_R21', 'Region_R22', 'Region_R23',\n",
    "                          'Region_R24', 'Region_R25', 'Region_R26', 'Region_R31',\n",
    "                          'Region_R41', 'Region_R42', 'Region_R43', 'Region_R52',\n",
    "                          'Region_R53', 'Region_R54', 'Region_R72', 'Region_R73',\n",
    "                          'Region_R74', 'Region_R82', 'Region_R83', 'Region_R91',\n",
    "                          'Region_R93', 'Region_R94',\n",
    "                          'Area_ord']\n",
    "    if drop:\n",
    "        column_trans_names = [i for i in column_trans_names if i not in\n",
    "                              ['VehPower_4', 'VehAge_[1, 10]', 'DrivAge_[41,51)',\n",
    "                               'VehBrand_B1', 'VehGas_Diesel', 'Region_R24']]\n",
    "    return column_trans, column_trans_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_tranformer, col_transformer_names = gen_col_trans(drop=False, standardize=False)\n",
    "X = col_tranformer.fit_transform(df)\n",
    "\n",
    "y = df[['PurePremium', 'Frequency', 'AvgClaimAmount', 'Exposure']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test, X_train, X_test = train_test_split(df, X, random_state=0)\n",
    "\n",
    "df_train = pd.DataFrame(df_train, columns = df.columns)\n",
    "df_test = pd.DataFrame(df_test, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv', index=False)\n",
    "df_test.to_csv('df_test.csv', index=False)\n",
    "\n",
    "np.save('X_train.npy', X_train.toarray())\n",
    "np.save('X_test.npy', X_test.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
